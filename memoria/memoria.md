# Gobierno del dato para IoT

## Objetivos

Los objetivos se separan en dos tipos[1]:

- Por un lado, se identifican los objetivos que la gobernanza del dato va a aportar a nuestra organización, es decir qué aspectos son los que se verán mejorados en nuestra organización tras la aplicación de nuestro proyecto.

- Por otro lado, también es necesario definir los objetivos que el proyecto en sí ha de cumplir, qué aspectos de el gobierno del dato se van a tratar.

### ¿Qué nos aporta el gobierno del dato?

Los beneficios de aplicar un proyecto de gobierno del dato a cualquier organización son claros e inmediatos, con un efecto directo en la eficiencia, seguridad y desarrollo.

Entre los objetivos que buscamos se encuentran los siguientes:

1. Mejora de los datos: de forma que no solamente se obtienen datos de mayor calidad, sino que son más confiables.

   1. Utilizamos estándares que nos ayudan a medir y cumplir con la calidad

   2. Se monitorizan los datos de forma continua para garantizar el cumplimiento

2. Cumplimiento de las normativas pertinentes, y mejora de la seguridad en general

3. Optimización del uso de los datos, consiguiendo que las operaciones diarias sean más rápidas

4. Mejora de la organización, dotando a todo el mundo de una visión unificada del significado y uso de los datos

### Objetivos a desarrollar en el proyecto

Los objetivos de este proyecto para alcanzar los definidos en el anterior apartado son los siguientes:

1. Definición del alcance del proyecto

2. Identificación del equipo de gobierno del dato y sus funciones

3. Crear las políticas y estándares a implementar

4. Definir y clasificar los datos

5. Definir los procesos de recopilación, uso y almacenado de los datos

6. Estudiar las herramientas a utilizar, realizando un estudio de mercado de las mismas

   1. Con especial énfasis en herramientas de catálogo de datos

7. Identificar las métricas, indicadores y condiciones de cumplimiento necesarias para una correcta monitorización del dato y sus procesos

8. Definir los procesos de revisión y mejoras del proyecto

## Alcance

### Contexto

El gobierno del dato es un aspecto clave en cualquier organización, pero tiene un carácter especialmente importante en el ámbito de el IoT (Internet de las Cosas). No solo se parte desde una situación en la que los dispositivos IoT son cada vez más, sino que cuenta con bastantes retos que son claves desde una perspectiva de gobierno del dato. Por ejemplo la generación masiva de datos que estos dispositivos conllevan, o la heterogeneidad de las fuentes. A esto se le añaden agravantes como la necesidad de procesamiento de los datos en tiempo real y la necesidad de una mayor seguridad.

### Actores implicados

El gobierno del dato ha de implicar no sólo a los actores directos del proyecto, sino que es algo en lo que toda la organización ha de aportar y concienciarse. Sin embargo, sí que hay ciertos departamentos que son de vital importancia:

- Dirección, dado que han de mostrar su apoyo para que el proyecto cuente con los recursos necesarios

- Departamento de las tecnologías de la información, por su conocimiento técnico

  - Especial mención a el área de la seguridad como expertos de la protección de datos

- Departamento legal, por su conocimiento de las leyes y normativas pertinentes

- Responsables de operaciones y producto, por su conocimiento del negocio y el uso de los datos en el día a día

- Equipos de desarrollo, ya que son los encargados de construir las soluciones que hacen uso de los datos

De la misma manera, se definirá un equipo del gobierno del dato en un apartado posterior. Estas serán las personas principales encargadas de llevar a cabo el proyecto. Para ello se definirán roles específicos y se acotarán las responsabilidades de cada uno.

## Equipo

El equipo de gobierno del dato se puede separar en 3 grupos principales: el consejo de gobernanza del dato que tomará las decisiones a alto nivel, el grupo de coordinación y luego un grupo reducido por cada área de negocio[2].

### Consejo de gobierno del dato

El consejo ha de ser formado por miembros de la organización con capacidades para asignarle tanto recursos como los fondos necesarios y miembros que vayan a ser los encargados de tomar las decisiones sobre políticas y procesos. Como tercer grupo minoritario también se contará con gente relacionada a los procesos de negocio, aunque no sean miembros principales aportarán su conocimiento sobre el negocio en momentos en los que se necesite.

Sus principales responsabilidades son las siguientes[3]:

- Definir los estándares, como puede ser para las definiciones, formatos, o nomenclaturas

- Definir las métricas de monitorización y los procesos de correcciones en caso de incumplimientos

- Definir las políticas de acceso a datos y seguridad

En aspectos generales, el rol principal consiste en decidir cuales son los objetivos y metodologías principales a utilizar.

### Grupo de coordinación

Este grupo contará con miembros que también participan en el consejo, quienes se encargan de definir las políticas a seguir han de definir los requisitos específicos que se han de lograr para lograr los objetivos a alto nivel decididos en el consejo. Funcionará como un intermediario entre la dirección de alto nivel del consejo y los grupos de áreas específicos, marcando las acciones que los grupos de áreas han de realizar y retransmitiendo al consejo los resultados y comentarios de las áreas al consejo.

### Grupos de áreas

Formando parte de cada área de negocio, este grupo une a ciertos miembros de el grupo de coordinación con interesados y personal técnico de las áreas de negocio. Estos serán los encargados de implementar las órdenes de trabajo específicas que lleven al cumplimiento de los requisitos definidos.

### Roles

La la formación de estos grupos definiremos varios roles, cada persona implicada en el proyecto contará con un rol, y formará parte de uno o varios grupos [4].

#### Patrocinador ejecutivo

Será el líder del proyecto, encargado de asignar los suficientes fondos y recursos que se acuerden en el consejo. Toma carácter de guía de la estrategia que ha de seguir el proyecto.

#### Líder del gobierno del dato

Es el responsable máximo de que se lleve adelante la implementación del proyecto. Por lo tanto sus responsabilidades son de coordinar y guiar al equipo, como jefe de proyecto.

#### Propietario del dato

El propietario del dato es quien tiene autoridad para realizar las decisiones sobre las definiciones de términos de negocios y requerimientos que el negocio tiene sobre el dato

#### Data steward

Los data steward son los encargados de trasladar los requerimientos específicos y actúan como sus representantes en la reuniones del día a día. Son gente de los diferentes departamentos que trabajan bajo la coordinación del propietario del dato.

#### Interesados

Son los representantes de los afectados por las políticas y acciones que se definen y realizan a causa del proyecto. Por un lado se encargan de transmitir la información pertinente a los usuarios y consumidores de los datos, y también se encargan de recoger todas las dudas, comentarios y opiniones de éstos.

#### Custodios

Se trata de un rol técnico que consiste en el mantenimiento de los datos, por lo tanto la implementación técnica de todas las políticas y procesos que se definen, así como de los arreglos y mejoras que se necesiten según se especifique en la monitorización

### Organización de los roles en los equipos

Ya definidos tanto los grupos como los roles, se especifica la organización de la siguiente manera

| Grupo                         | Roles                                                                                                                       |
| ----------------------------- | --------------------------------------------------------------------------------------------------------------------------- |
| Consejo del gobierno del dato | Patrocinador ejecutivo<br/>Líder de gobierno del dato<br/>Propietario del dato<br/>Personas claves de entre los interesados |
| Grupo de coordinación         | Líder de gobierno del dato<br/>Propietario del dato<br/>Data stewards<br/>Personas claves de entre los interesados          |
| Grupos de áreas               | Data stewards<br/>Custodios<br/>Interesados                                                                                 |

## Formación de data stewards

Los data stewards son un perfil con alto conocimiento de ingeniería de datos, para poder realizar la función de data steward sí que se requerirá alguna de las siguientes formaciones:

- Grado en Ingeniería Informática

- Grado en Ingeniería en Tecnología de Telecomunicación

- Grado en Matemáticas

- Grado en Ciencia de Datos

- Algún otro grado equivalente

Además de los estudios de grado hay ciertos posgrados que también ayudarán en la formación:

- Máster en Big Data

- Máster en Ciberseguridad

- Máster en Ingeniería del Software

Es importante que la organización busque políticas para fomentar este tipo de estudios, como ayudas económicas o conciliación de horarios. Sin embargo, no es realista esperar que los data stewards inviertan tanto tiempo, recursos y energías en formaciones tan extensas, ni se puede permitir ninguna organización los recursos ni tiempo completos que requieren. En España sí que existen varias organizaciones que ofrecen diferentes certificaciones en el ámbito del gobierno del dato, aunque ninguna de ellas es una certificación estandarizada, todas ellas son propias de las instituciones que las imparten. Estas sí que pueden considerarse como una buena opción para compaginar con el trabajo, dado sus precios más reducidos y duración asumible. Por lo tanto se ofrecerá a los data stewards la opción de cursar estos diferentes cursos y obtener sus correspondientes certificaciones:

- Data Stewardship y gestión de datos de

investigación

- Ofrecido por Sociedad Española de Documentación e Información Científica (SEDIC)

- En castellano

- De carácter virtual

- Duración de 60h

- Certified Data Steward

  - Ofrecido por eLearningCurve

  - En inglés

  - De carácter virtual

  - Duración de 20h

- Curso de Talend Data Stewardship

  - Ofrecido por eLearningCurve

  - En castellano

  - Virtual o presencial en 4 localizaciones (Bilbao, Madrid, Málaga o Barcelona)

  - Duración de 14h

De la misma forma que se sugieren estos cursos, existirá la opción de los data stewards de solicitar otros alternativos que crean pertinentes, bajo la aprobación de su jefe de proyecto.

## Estándares

De cara a crear un glosario de términos, es una buena práctica no intentar partir de 0, sino utilizar estándares ya existentes como base. Para ello, se ha realizado un estudio de diferentes estándares para ver sus diferentes carácterísticas y poder decidirse por uno de ellos

### Ontología dedicada a campos específicos

No se consideran como soluciones a nuestras necesidades, dado que no tienen uso directo fuera de sus campos. Algunos ejemplos a continuación:

| Nombre                   | Dominio                                                                                                                                          | Documentación                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |
| ------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Agronomy Ontology (AgrO) | Agronomía                                                                                                                                        | https://bigdata.cgiar.org/resources/agronomy-ontology/                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |
| Brick                    | Construcción                                                                                                                                     | https://brickschema.org/                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
| ExtruOnt                 | Industria , concretamente máquinas de extrusión                                                                                                  | https://arxiv.org/pdf/2401.11848                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |
| SAREF                    | Es un grupo de varios proyectos cada uno con su dominio: Automovilismo, construcción, ciudades, salud, energía, medio ambiente, industria, aguas | https://www.etsi.org/deliver/etsi_ts/103400_103499/10341007/01.01.01_60/ts_10341007v010101p.pdf<br/>https://www.etsi.org/deliver/etsi_ts/103400_103499/10341003/01.01.02_60/ts_10341003v010102p.pdf<br/>https://www.etsi.org/deliver/etsi_ts/103400_103499/10341004/01.01.02_60/ts_10341004v010102p.pdf<br/>https://www.etsi.org/deliver/etsi_ts/103400_103499/10341001/01.01.02_60/ts_10341001v010102p.pdf<br/>https://www.etsi.org/deliver/etsi_ts/103400_103499/10341002/01.01.02_60/ts_10341002v010102p.pdf<br/>https://www.etsi.org/deliver/etsi_ts/103400_103499/10341005/01.01.02_60/ts_10341005v010102p.pdf<br/>https://www.etsi.org/deliver/etsi_ts/103400_103499/10341010/01.01.01_60/ts_10341010v010101p.pdf<br/> |

### Ontology Modeling for Intelligent Domotic Environments (DogOnt)

Es un sistema ontológico principalmente orientado al entorno de la domótica, pero que también es utilizado como estándar genérico.

| Alcance       | Orientado a redes locales de dispositivos IoT |
| ------------- | --------------------------------------------- |
| Documentación | https://iot-ontologies.github.io/dogont/      |
| Licencia      | Apache License, Version 2.0                   |

### IoT-Lite

IoT-Lite es un sistema de representación de recursos de IoT con el objetivo de ser de amplio alcance y al mismo tiempo ligero. Por lo que puede ser de utilidad cuando se quieren mezclar conceptos de diferentes ámbitos de las IoT.

| Alcance       | Lo más amplio posible, aplicable a cualquier ámbito         |
| ------------- | ----------------------------------------------------------- |
| Documentación | https://www.w3.org/submissions/2015/SUBM-iot-lite-20151126/ |
| Licencia      | Creative Commons Attribution 3.0 Unported License           |

### Web of Things Thing Description (WoT-TD)

Otro estándar orientado a uso general para cualquier ámbito de las IoT, con el objetivo específico de integrar los dispositivos IoT en un contexto Web of Things. Es decir dispositivos accesibles desde internet.

| Alcance       | General, Web of Things                                   |
| ------------- | -------------------------------------------------------- |
| Documentación | https://wot-td-ontology.github.io/wot-thing-description/ |
| Licencia      | W3C Software and Document License                        |

### FIESTA-IoT

Centrado en la privacidad, y en soportar los frameworks de pruebas de los dispositivos IoT. Pero sin dejar de lado el modelar las IoT de forma amplia y genérica.

| Alcance       | General, aunque con especial énfasis en privacidad y testbeds. |
| ------------- | -------------------------------------------------------------- |
| Documentación | https://ieeexplore.ieee.org/abstract/document/7845470          |
| Licencia      | Copyright EU H2020 FIESTA-IoT                                  |

### Machine-to-Machine Measurement (M3)

Creado con el objetivo de utilizar un lenguaje unificado que compartan todos los sensores de dispositivos de todos los ámbitos.

| Alcance       | General                                                              |
| ------------- | -------------------------------------------------------------------- |
| Documentación | http://www.eurecom.fr/fr/publication/4553/download/cm-publi-4553.pdf |
| Licencia      | GNU GPLv3 license                                                    |

### Comparativa

Para realizar una selección de qué estándar utilizar, se ha decidido utilizar 4 cualidades. No todas necesariamente de obligatorio cumplimiento al 100%:

- Aplicable a un ámbito general: en este contexto significa que no está diseñado para un ámbito específico, y se considerará mejor según más tipos de elementos, propiedades y valores sea capaz de modelar. En este caso sólo DogOnt no es del todo aplicable a todos lo dominios, aunque sigue su desarrollo para que en algún momento lo sea. Y por otro lado M3 tiene un diseño que modela ciertas unidades, sensores y dominios, por lo que podría darse el caso de que no cumpliera todas nuestras necesidades.

- Suficientemente desarrollado: implica que está listo para ser utilizado en aplicaciones productivas ya. En el caso de los estándares propuestos, todos están ya lo suficientemente

desarrollados, exceptuando a DogOnt que sigue en el desarrollo previamente mencionado de pasar de un dominio específico a un ámbito genérico.

- Licencia permisiva: se valorará que cuente con una licencia que no nos vaya a limitar en su uso, ni condicione ser parte de ninguna organización.

- Utilizado en el marco europeo: la cualidad más subjetiva de las 4, aunque sí se considera útil el saber que proyectos y empresas en un marco europeo similar al nuestro lo están ya utilizando

|            | Aplicable a un ámbito general                      | Suficientemente desarrollado                   | Licencia permisiva        | Utilizado en el marco europeo                       |
| ---------- | -------------------------------------------------- | ---------------------------------------------- | ------------------------- | --------------------------------------------------- |
| DogOnt     | En proceso de expandirse del ámbito de la domótica | En proceso de desarrollo de su segunda versión | Sí                        | No extendido                                        |
| IoT-Lite   | Sí                                                 | Sí                                             | Sí                        | Sí, desarrollado como parte de la iniciativa EU FP7 |
| WoT-TD     | Sí                                                 | Sí                                             | No                        | Presencia en entidades europeas                     |
| FIESTA-IoT | Sí                                                 | Sí                                             | Sólo bajo previa petición | Sí                                                  |
| M3         | Sí, aunque tiene una estructura muy rígida         | Sí                                             | Sí                        | Sí                                                  |

Como conclusión, IoT-Lite es la que mejor balancea las 4 cualidades que buscamos, por lo que sería nuestra primera opción. De carácter abierto a todos los dominios y sin limitaciones con ningún dispositivo que nos vayamos a encontrar, cuenta con una licencia que no nos limita en ningún aspecto y sabemos que ha sido desarrollado y se está utilizando en un marco como el nuestro.

### Funcionamiento de IoT-Lite

IoT-Lite es una extensión de Semantic Sensor Network Ontology (SSN) y utiliza qu-taxo (herramienta de taxonomía) para definir unidades y cantidades[5]. Categoriza los 3 elementos en 3 clases fundamentales:

- Objetos, entidades IoT

  - Pueden tener ubicaciones (puntos en el espacio físico)

  - Pueden tener atributos y estos esta asociados con dispositivos

- Sistemas, abstracción que representa infraestructura. Puede tener componentes y al mismo tiempo subsistemas (que a su vez son de tipo sistema)

  - Estos componentes o dispositivos a su vez pueden ser de diferentes tipos:  dispositivos sensores, dispositivos de etiqueta (como puede ser un código QR o chip RFID)

  - Los dispositivos sensores son a su vez también elementos de tipo "sensor" que pueden contener sub-sensores. Lo que estos dispositivos captan se define mediante objetos de tipo unidad y cantidad

  - Los dispositivos también pueden tener cobertura (define su rango de actuación) y esta se define mediante utilizando lo siguiente

    - Puntos, que representan puntos en el espacio físico

    - El sub-tipo de el elemento cobertura nos indica como utilizar los puntos para dibujar el alcance

      - Círculo

      - Rectángulo

      - Polígono

- Servicios, que son proporcionados por dispositivos IoT

## Políticas

A continuación definimos las políticas que se han definido, organizadas en las siguientes categorías [6]:

- Políticas de calidad

- Políticas de privacidad

- Políticas de seguridad

- Políticas de la vida del dato

- Políticas éticas

- Políticas de definiciones

### Políticas de calidad

El reto principal de la calidad en el contexto de IoT viene dada la alta cantidad de datos y los heterogeneidad. Para ello es vital definir políticas que por un lado minimicen los posibles problemas de origen, y también realizar validaciones periódicas: A continuación se definen algunas de las políticas de este aspecto:

| Política                                                                                                                                                                                                                                                                                                 | Responsable                                                                                                                                                                                                                                                                                                                                                                                                                                                            | Momento de aplicación                                                                                            |
| -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------- |
| Comparación de la información de los sensores con datos de referencia. Por ejemplo si tenemos sensores de lluvia comprobar que coincida con información meteorológica de referencia.                                                                                                                     | Proceso automatizado, los márgenes de diferencias serán marcados por el data steward, mientras que la implantación será de mano del custodio.                                                                                                                                                                                                                                                                                                                          | Periódica, diario como proceso automatizado fuera del horario laboral.                                           |
| Validación de las unidades utilizadas por los nuevos orígenes de datos.                                                                                                                                                                                                                                  | EL custodio es el encargado de validar que cada nuevo origen que añada al sistema utilice las mismas unidades que los demás. Dichos estándares son los especificados por el data steward. Indican por ejemplo que los pesos han de especificarse en gramos, el tiempo en mili-segundos y la temperatura en grados Celsius. En caso de que el origen no cumpla por defecto, el custodio habrá de implementar la conversión de los datos antes de empezar a almacenarlos | Al momento de incorporar un nuevo origen de datos al sistema                                                     |
| Inspección visual de la información. No de forma exhaustiva, pero sí que ha de combinarse con las validaciones automáticas para poder encontrar casos que no se estén validando bien                                                                                                                     | El encargado es el data steward del área, ya que cuenta tanto con los conocimientos del negocio como de los estándares que se han marcado.                                                                                                                                                                                                                                                                                                                             | Periódica, semanal                                                                                               |
| Calibración de los sensores                                                                                                                                                                                                                                                                              | Personal técnico                                                                                                                                                                                                                                                                                                                                                                                                                                                       | Periódico, según las especificaciones del fabricante                                                             |
| Implementación de redundancia en los sensores. En los casos que sea posible, utilizar sensores redundantes para la validación del correcto funcionamiento de cada uno de ellos. No sólo para la validación, sino el poder continuar con la recolección de datos en caso de fallo de uno de los sensores. | Custodios del dato, personal técnico                                                                                                                                                                                                                                                                                                                                                                                                                                   | Crear la redundancia en cuanto sea posible, después una vez esté implementada la validación ha de ser automática |

### Políticas de privacidad

En el aspecto de la privacidad, las pautas principales en el ámbito de la Unión Europea las marca el Reglamento General de Protección de Datos (GDPR) [7]. A la hora de identificar si algún dato es de carácter privado es necesario utilizar la definición que nos indica [8]. A grandes rasgos se trata de información relacionada a una persona física (es decir, no aplicable a  que sea identificada o que pueda ser identificada mediante un punto o varios de información. Bajo esta definición queda claro que muchísima de la información que capturan los dispositivos IoT cae bajo esta categoría. Sí que hay información que no es de este tipo, como puede ser:

- Información meteorológica en general

- Sensores de maquinaria industrial, o sensores de información anónima como puede ser la humedad en una planta industrial

- Sensores de movimiento en lugares públicos que no capten ninguna información que identifique a las personas (por ejemplo para contar el número de posibles clientes que entra a una tienda)

Por  el otro lado, ejemplos muy usados en IoT que sí son de tipo privado:

- Cualquier dispositivo médico que monitorice a una persona

- Máquinas de fichaje de entrada y salida del trabajo en una planta industrial

- Dispositivos que localicen a una persona en el espacio/tiempo

El GPR también contempla un tipo de información extra sensible, que hemos de tratar con especial cuidado, siendo esta información de tipo:

- Genética

- Biométrica

- De salud

- Información personal que pueda revelar raza u origen étnico, opiniones políticas religiosas o ideológicas o que revelen pertenencia a sindicatos.

| Política                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | Responsable                                                                                                                                                                                                                   | Momento de aplicación                                                     |
| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------- |
| Identificar información privada. Se ha de identificar todos los orígenes que nos nutran de información que se considere privada. Se deberá ejecutar en cuanto sea posible para información ya capturada y orígenes de datos ya utilizados, y siempre que se añada un origen de datos nuevo. Especial hincapié en que no hay que tratar los nuevos orígenes como puntos independientes, sino que hay que considerarlos en contexto para poder identificar si la nueva información puede ser combinada con otra ya existente para des-anonimizarla. | Data steward                                                                                                                                                                                                                  | Inmediato, siempre en el momento de añadir nuevos orígenes de información |
| No compartir información privada con otras organizaciones. Esto ha de ser aceptado por el líder del proyecto, ya que tiene que guiar también al negocio. Es posible compartir esta información con otras organizaciones bajo ciertas condiciones, pero siempre la opción por defecto ha de ser que esta información no sea compartida con nadie.                                                                                                                                                                                                  | Patrocinador ejecutivo: responsable de alinear a la organización con la política<br/>Líder de gobierno del dato: responsable de argumentar su importancia<br/>Data steward: responsable de identificar la información privada | A la hora de solicitudes de información desde otras organizaciones        |
| Notificación de la información utilizada. Es necesario notificar a la persona de la que se está capturando información. Esto implica, que las aplicaciones de nuestra organización informen al usuario de las mismas, se informen a los trabajadores y por último se informe a cualquier cliente.                                                                                                                                                                                                                                                 | Data steward: como supervisor<br/>Interesados: relacionados a las personas pertinentes<br/>Personal técnico, en caso de que se necesite alguna implementación de carácter técnico                                             | Siempre que alguna de las personas afectadas interactúe con nosotros      |
| Eliminación de la información bajo demanda de la persona a la que pertenezca esa información                                                                                                                                                                                                                                                                                                                                                                                                                                                      | Data steward: como supervisor<br/>Personal técnico, en caso de que se necesite alguna implementación de carácter técnico                                                                                                      | Bajo demanda, cada vez que una persona solicite su eliminación            |
| Cifrado de la información personal [9]. Como medida para minimizar los riesgos de una brecha de seguridad                                                                                                                                                                                                                                                                                                                                                                                                                                         | Custodios<br/>Personal técnico                                                                                                                                                                                                | Continua                                                                  |
| Creación de los casos de procesado de la información. Según la reguilación, es necesario especificar qué uso se le da a cada dato, por lo que es necesario identificar todos los usos que se den y actualizar cada vez que se cree un uso nuevo para que se pueda ejercer la política de notificación a la persona afectada.                                                                                                                                                                                                                      | Data steward<br/>Custodios                                                                                                                                                                                                    | Continua                                                                  |

### Políticas de seguridad

No existe un sólo estándar universal de políticas de seguridad, y al igual que en los demás tipos de políticas hemos de tener en cuenta nuestro ámbito. Internet Society [10] por ejemplo distingue 3 tipos de ámbitos según su desarrollo en las regulaciones de la seguridad:

- Desarrollo en fases iniciales: hay interés en el IoT, pero no existe una regulación aún.

- Desarrollo en estado intermedio: hay regulaciones, pero no contemplan el IoT o no se ejercen dichas regulaciones

- Desarrollo avanzado: existen las regulaciones, son aplicables al IoT y hay cuerpos dedicados a ejercer su cumplimiento

Viendo estas tres categorías queda claro que cualquier país de la Unión Europea cae bajo la categoría de desarrollo avanzado, e Internet Society mismo sugiere unas acciones a realizar que pueden guiar nuestras políticas.

| Política                                                                                                                                    | Responsable                                                                                                                                                                                                                        | Momento de aplicación                                                           |
| ------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------- |
| Revisión periódica de las regulaciones de seguridad. Que pueden incorporar requisitos para defenderse de nuevos riesgos y vulnerabilidades. | Líder de gobierno del dato<br/>Propietario del dato<br/>Data steward<br/>En general se trata de un equipo mixto que sea capaz de hacer cumplir lo acordado y que al mismo tiempo tenga algo de conocimiento específico del negocio | Periódica, con carácter mensual                                                 |
| Asignación de responsables para los diferentes sistemas                                                                                     | Líder de gobierno del dato<br/>Data steward<br/>Custodios                                                                                                                                                                          | Cada vez que se realicen modificaciones en el equipo o en la propiedad del dato |
| Creación de protocolos en caso de una situación de violación de datos                                                                       | Data steward y custodios asignados como responsables en la política anterior                                                                                                                                                       | Creación inmediata, con 2 revisiones anuales                                    |

### Políticas de la vida del dato

Estas políticas se aplican en los diferentes puntos de la vida del dato, y aunque es cierto que existe cierto solapamiento con otras categorías, es importante que se reflejen en las políticas los retos que afectan especialmente a el IoT[11]. Se hace especial hincapié en las etapas que son especialmente complejas en este ámbito; como por ejemplo la colección del dato, ya que vienen de fuentes, maneras y formatos mucho más heterogéneos que en la mayoría de otros ámbitos. Aunque por supuesto se han de considerar todas las fases.

Algunas fases del ciclo de vida que ya se cubren en anteriores políticas:

- Creación, colección y limpieza: se aplican las políticas de calidad del dato relacionadas con la estandarización y veracidad de la información.

- Almacenamiento: se deben seguir las políticas de seguridad para garantizar su seguridad física (daño del lugar de almacenado) y de acceso (no haya accesos indebidos o hacking)

- Procesado: Aplicados en el contexto de la privacidad

- Retención: Se aplican las políticas de privacidad. Estas especifican los datos que no se pueden retener, por ejemplo alguien que solicita su eliminación según lo especificado en el GDPR

Como ejemplo de alguna política no considerada en el apartado anterior:

| Política                                                                                                                                                                                                                           | Responsable                 | Momento de aplicación       |
| ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------- | --------------------------- |
| Purga de datos innecesarios. Ha de ser una decisión tomada entre los data stewards correspondientes y los custodios, para realizar la decisión de qué datos han dejado de ser relevantes para el negocio y  pueden ser eliminados. | Data stewards<br/>Custodios | Periódica de carácter anual |

### Políticas éticas

En lo relacionado a la ética, principalmente atañe a un cumplimiento correcto de la privacidad y seguridad anteriormente especificadas. Sin embargo es correcto también la revisión periódica de los usos y captura de los datos para revaluar estos procesos, tanto de cara a tener un trato más justo hacia las personas a las que atañe la información como para intentar adelantarnos a posibles regulaciones futuras.

| Política                                                                                                             | Responsable                                 | Momento de aplicación       |
| -------------------------------------------------------------------------------------------------------------------- | ------------------------------------------- | --------------------------- |
| Reuniones periódicas para la creación de directrices éticas que expandan los requisitos mínimos exigidos legalmente. | Líder de gobierno del dato<br/>Data steward | Periódica de carácter anual |

### Políticas de definiciones

Implican principalmente la creación de los estándares de nomenclatura que ha de seguir todo el mundo, y el uso de dicha nomenclatura por todos los usuarios de la información.

| Política                                                                                                                                          | Responsable               | Momento de aplicación |
| ------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------- | --------------------- |
| Creación y mantenimiento de un catálogo de datos. En el se definirán las nomenclaturas a utilizar.                                                | Data stewards             | Continua              |
| Utilización de las nomenclaturas especificadas en el catálogo de datos. No será permisible utilizar nomenclaturas que no estén definidas en este. | Custodios<br/>Interesados | Continua              |

## Gestión de prácticas y políticas

Para realizar una buena gestión de todo lo implementado y verificar su funcionamiento se realizarán reuniones bianuales. Estas reuniones las realizará el consejo de grupo de coordinación para evaluar el grado de implantación de las prácticas y políticas definidas y valorar su efectividad. Para ello los data stewards de cada área deberán realizar una auditoría sobre su área y compartir los resultados con el líder del gobierno del dato. Deberán cubrir los siguientes aspectos:

- Nivel de implantación del plan

  - Y los problemas encontrados que puedan estar retrasando su implantación

- Eficacia de las acciones tomadas

  - Se deberá poner especial énfasis en las más y menos eficaces

- Comentarios y sugerencias recibidas

De los puntos en los que se han notado carencias o problemas será necesario distinguir qué tipo de solución es suficiente:

- Si se considera solucionable mediante medios técnicos o formas de implantación, el responsable de dicha acción seguirá siendo el encargado de realizar lo necesario. Para ello puede solicitar orientación de otros miembros del grupo o usar alguno de los casos de éxito como referencia

- En caso de ser un problema que requiere más recursos o de un cambio en la estrategia del proyecto, será necesario realizar un informe con las deficiencias y necesidades. Este será redactado por el líder del dato y llevado a discusión a el consejo del dato

De la misma manera, el consejo del dato se reunirá también con la misma cadencia, después de la anterior reunión. En ella se tratará el avance de el proyecto y se discutirán las mejoras que requieran de cambios a nivel estratégico o de recursos. En caso de llegar a un acuerdo el líder del dato se encargará de llevar de vuelta estas decisiones a los data stewards.

### Auditorías

Las auditorías son una de las herramientas clave para valorar la correcta implementación y uso de nuestro sistema. Es una forma de garantizar que se cumplan los objetivos marcados, observando qué aspectos están progresando adecuadamente y cuales no han progresado o no están funcionando como deberían. Es el origen del que surgirán todas las acciones de mejora continua.

Las auditorías pueden realizarse en 4 fases [12]:

1. Preparación: implica la definición de objetivos, alcance y plan de acción

2. Participación de los interesados: definición de los roles, identificación de todos los interesados

3. Ejecución: Se obtiene la información y se analiza

4. Resultados: Se presentan los resultados

De cara a realizar una buena auditoría también es necesario definir que preguntas son clave realizar durante las auditorías, The Institute of Internal Auditors sugiere varias para su uso en el ámbito de el gobierno del dato [13]:

- ¿Saben las personas afectadas que se está recopilando su información?

- ¿Se está inventariando toda la información que recopilamos?

- ¿Se están cumpliendo nuestros estándares para la calidad?

- ¿Son las soluciones técnicas correctas y adecuadas?

- ¿Es la seguridad actual suficiente?

- ¿Son las prácticas de gobierno del dato utilizadas suficientemente maduras?

- ¿Se está formando a los trabajadores en el aspecto ético de el gobierno del dato?

## Regulaciones

La ley principal en España que regula el dato es la "Ley Orgánica de Protección de Datos Personales y garantía de los derechos digitales"[14], que así mismo se trata de una adaptación al ámbito nacional de la ley de la Unión Europea "Reglamento General de Protección de Datos"[7] (GDPR por sus siglas en inglés).

Este marco define muchos de los aspectos que ya hemos tratado, como son:

- Qué se considera un dato privado

- Necesidad de información la persona sobre qué datos suyos se utilizan y cómo se utilizan.

- Necesidad de consentimiento para recopilar información no estrictamente necesaria para el funcionamiento básico de los servicios aportados

- Limitaciones a la hora de compartir datos personales con otras organizaciones

- "El derecho al olvido" o el poder de las personas a exigir que sus datos sean eliminados

- Aplicación de medidas de seguridad suficientes, como puede ser la anonimización o seudonimización de los datos

- Sanciones en caso de incumplimiento

- Exenciones, como puede ser para cumplimiento de otra ley, uso personal o seguridad nacional

Al ser una ley se trata por lo tanto de algo con un cumplimiento obligatorio, no pautas a usar de referencia sino  unos estándares mínimos que han de ser cumplidos en todos los casos menos en las exenciones contempladas.

## Especificaciones

Las especificaciones a diferencia de las leyes, no son de aplicación obligatoria, pero siempre es una buena práctica el utilizar estándares de referencia. En España los estándares de referencia son las especificaciones UNE [15] (Una Norma Española). En particular en el ambiente de gobierno del dato las aplicables son las siguientes:

- UNE 0077:2023 Gobierno del dato

- UNE 0078:2023 Gestión del dato

- UNE 0079:2023 Gestión de la calidad del dato

### UNE 0077:2023

Es una especificación a nivel estratégico, diseñada para guiar la toma de decisiones a la hora de definir los objetivos

del proyecto de gestión del dato. Por lo tanto se tendrá en cuenta tanto los objetivos a nivel general del proyecto, como las definiciones de las políticas que habrán de ser implementadas. Esto implica que es del dominio de todos los roles del consejo del gobierno del dato.

Esta especificación está dividida en 5 procesos [16].

| Proceso                                                                               | carácterísticas                                                                                                                                                                                         |
| ------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Establecimiento de la estrategia del dato                                             | Es el primer paso, en el que se identifican las capacidades de la organización, los datos usados por la misma, los contextos en los que se usan y se elabora un plan general de gobierno del dato.      |
| Establecimiento de políticas, buenas prácticas y procedimientos del dato              | Es el paso en el que se definen las políticas de gobierno del dato que se van a implementar, las regulaciones y estándares que nos afectan.                                                             |
| Establecimiento de estructuras organizativas para el gobierno, gestión y uso del dato | Se analiza la estructura de la organización y como el uso del dato está dividido entre las diferentes partes. También se define el equipo, roles y responsabilidades del proyecto de gobierno del dato. |
| Optimización de los riesgos del dato                                                  | Identificación, evaluación, mitigación de los riegos del dato, definición de las políticas de seguridad y privacidad.                                                                                   |
| Optimización del valor del dato                                                       | Consiste en la maximización del valor de los datos,  alineándolos los objetivos estratégicos de la organización y realizando una buena gestión en su uso.                                               |

### UNE 0078:2023

Mientras que UNE 0077:2023 era de carácter más estratégico, esta resalta más los procesos relacionados con las acciones que se van a llevar a cabo para realizarlos. Es decir por ejemplo de una política que se ha decidido implementar, que acciones va a realizar su responsable para que esta se cumpla. Esta especificación por lo tanto tendrán que tenerla más presente los integrantes de los grupos de áreas.

La especificación define 13 procesos a tener en cuenta [17], cada uno relacionado con un aspecto técnico de la gestión del dato:

1. Procesamiento del dato

2. Gestión de la infraestructura tecnológica

3. Gestión de requisitos del dato

4. Gestión de la configuración del dato

5. Gestión de datos histórico

6. Gestión de seguridad del dato

7. Gestión del metadato

8. Gestión de la arquitectura y diseño del dato

9. Compartición, intermediación e integración del dato

10. Gestión del dato maestro

11. Gestión de recursos humanos

12. Gestión del ciclo de vida del dato

13. Análisis del dato

### UNE 0079:2023

Este estándar define 4 procesos que hemos incorporado en nuestro proyecto [18], todos ellos dedicados a la mejora continua del dato, al ser una mezcla de procesos estratégicos y técnicos algunas veces serán más del ámbito de unos roles u otros del equipo:

| Proceso                                      | carácterísticas                                                                                                                                   | Tipo        |
| -------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------- | ----------- |
| Planificación de calidad del dato            | Es la planificación llevada a cabo para cumplir con el resto de los procesos. Se especifican objetivos, responsabilidades y las acciones a seguir | Estratégico |
| Control y monitorización de calidad del dato | Es la monitorización continua del dato                                                                                                            | Técnico     |
| Aseguramiento de calidad del dato            | Se definen los procesos para identificar los datos que no estén cumpliendo con los requisitos mínimos decididos.                                  | Estratégico |
| Mejora de calidad del dato                   | Se interviene en caso de que no se estén cumpliendo los mínimos de calidad.                                                                       | Técnico     |

Los procesos identificados como estratégicos van a ser responsabilidad principalmente de los data stewards, mientras que los custodios serán los principales responsables de los técnicos.

## Clasificación del dato

Expandiendo los conceptos tratados en el apartado de políticas de privacidad, dividiremos los datos en 4 categorías, dependiendo de su grado de privacidad y de si se trata de información interna de la organización. La privacidad se definirá según la regulación GDPR [7], mientras que la información interna será por decisión de los encargados del negocio.

### Personal

Se considerará personal la información que cumpla las siguientes carácterísticas, siguiendo su definición en el Artículo 4 (1) del GDPR [19]

- Es información relacionada a una persona física

  - Es decir, excluye a las personas jurídicas

- Que identifican a dicha persona

  - De manera directa

  - De manera indirecta, mediante la unión de varios datos

  - En particular hace especial hincapié en identificación mediante

    - Nombre

    - Número de identificación

    - Localización

    - Identificador online

    - Direcciones IP

    - O la unión de datos que sean específicos a una persona, como puede ser carácterísticas físicas, fisiológicas, genéticas, mentales, económicas, culturales, o sociales.

- Información que es tanto objetiva, como subjetiva (por ejemplo, opiniones o pareceres). Aunque sí es cierto que en el ámbito de las IoTs la mayoría va a ser información objetivo, como puede ser la recogida mediante diferentes sensores

- Es relacionada a una persona viva

  - Se considera que el derecho se aplica desde el nacimiento hasta la muerte de una persona

La ley hace referencia a "cualquier información", por lo que ha de interpretarse de la manera más amplia posible, en caso de duda se considerará personal.

Una vez identificada la información que cumple dichas condiciones se le asignan diferentes requisitos:

| Contexto                          | Requisito                                                                              |
| --------------------------------- | -------------------------------------------------------------------------------------- |
| Tipo de almacenado                | Siempre en servidor, nunca en almacenamiento extraíble (USBs, discos duros portátiles) |
| Localización  física              | Siempre dentro de la organización                                                      |
| Encripción                        | Siempre                                                                                |
| Control de acceso                 | Estricto                                                                               |
| Destrucción de la información     | Bajo solicitud                                                                         |
| Prevención de pérdida             | Sí                                                                                     |
| Puede ser compartida con terceros | No                                                                                     |
| Logging                           | Sólo si se anonimiza previamente                                                       |

### Sensible

Es un nivel por encima de la información personal, que como su nombre indica se trata de datos que pueden ser más sensibles.

Se considera que es información sensible cuando:

- Cumple las condiciones para ser información personal

- Y encima es de una de las siguientes categorías:

  - Genética

    - El Artículo 4 (13) del GDPR [19] la define como información de carácterísticas genéticas que ha heredado o desarrollado una persona, en particular la información obtenida mediante el análisis de una muestra biológica

  - Biométrica

  - - El Artículo 4 (14) del GDPR [19] la define como información relacionada a las carácterísticas físicas, fisiológicas o de comportamiento de una persona

  - De salud

    - El Artículo 4 (15) del GDPR [19] la define como información relacionada a la situación de salud física o mental de una persona, incluyendo las prestaciones de servicios de salud

  - Información personal que pueda revelar raza u origen étnico, opiniones políticas religiosas o ideológicas o que revelen pertenencia a sindicatos.

Por lo tanto se establecen una condiciones aun más restrictivas que con la información personal no sensible:

| Contexto                          | Requisito                                                                              |
| --------------------------------- | -------------------------------------------------------------------------------------- |
| Tipo de almacenado                | Siempre en servidor, nunca en almacenamiento extraíble (USBs, discos duros portátiles) |
| Localización  física              | Siempre dentro de la organización                                                      |
| Encripción                        | Siempre                                                                                |
| Control de acceso                 | Muy estricto                                                                           |
| Destrucción de la información     | Bajo solicitud                                                                         |
| Prevención de pérdida             | Sí                                                                                     |
| Puede ser compartida con terceros | No                                                                                     |
| Logging                           | Nunca                                                                                  |

### Interna

Se trata de información que no es personal, pero que por decisiones de negocio no puede ser accedida por organizaciones externas de forma libre. Su clasificación se hace mediante la decisión de los responsables de negocio.

Su seguridad no compromete el cumplimiento de las regulaciones, pero sí que ha de protegerse para no afectar negativamente a la organización. Por lo tanto tendría ciertos requisitos, aunque menos estrictos que en el caso de información personal.

| Contexto                          | Requisito                                                                                                                         |
| --------------------------------- | --------------------------------------------------------------------------------------------------------------------------------- |
| Tipo de almacenado                | En servidor o equipos profesionales de los trabajadores<br/>En almacenamiento extraíble sólo en caso de estar propiamente cifrada |
| Localización  física              | El almacenamiento principal se realizará tanto en servidores propios de la organización como en datacenters contratados           |
| Encripción                        | Necesaria sólo en caso de usar medios de almacenados extraíbles                                                                   |
| Control de acceso                 | Medio                                                                                                                             |
| Destrucción de la información     | Según necesidades de negocio                                                                                                      |
| Prevención de pérdida             | Sí                                                                                                                                |
| Puede ser compartida con terceros | Sí, pero bajo permiso del propietario del dato                                                                                    |
| Logging                           | Permitido                                                                                                                         |

### Abierta

La información abierta o pública es la que ni es personal ni se considera que necesariamente ha de permanecer dentro de la organización. Su clasificación se hace mediante la decisión de los responsables de negocio.

Al ser abierta, los requisitos son los más laxos de todos.

| Contexto                          | Requisito                                                                                                               |
| --------------------------------- | ----------------------------------------------------------------------------------------------------------------------- |
| Tipo de almacenado                | Cualquiera                                                                                                              |
| Localización  física              | El almacenamiento principal se realizará tanto en servidores propios de la organización como en datacenters contratados |
| Encripción                        | No necesaria                                                                                                            |
| Control de acceso                 | Bajo                                                                                                                    |
| Destrucción de la información     | Según necesidades de negocio                                                                                            |
| Prevención de pérdida             | Sí, aunque se considera que puede ser compartida, no significa que su pérdida no sea un contratiempo                    |
| Puede ser compartida con terceros | Sí                                                                                                                      |
| Logging                           | Permitido                                                                                                               |

## Titularidad del dato

La titularidad del dato es un tema de especial complejidad en el ámbito del IoT, y no es un debate que tenga un consenso concreto a nivel global ni regional [20].

Para discutir sobre la titularidad del dato, es importante distinguir 3 tipos de actores:

- Los generadores del dato, que en el contexto de sensores y cualquier otra información generada por máquinas sería nuestra organización

- Las personas relacionadas a información, en caso de que la información sea de carácter personal. Es decir que un dato o conjunto de datos identifique a una persona segun lo definido en el apartado anterior

- Otros participantes, pueden ser los fabricantes de dispositivos IoT que utilizan sus propias plataformas para transmitir o almacenar los datos

Dado que no existe un framework estandarizado para la titularidad, se han de definir unas pautas a seguir para guiarnos:

1. Aunque la titularidad puede ser nuestra, hay ciertos derechos que las personas tienen sobre su información personal. Por lo que se ha de hacer un cumplimiento estricto de los derechos para con estas personas:

   1. Esto implica informar del uso y obtener el consentimiento cuando es necesario

   2. El derecho a las personas a obtener la información relacionada a ellas

   3. El derecho a solicitar que dicha información sea borrada, por lo que tiene que haber mecanismo para eliminar todos los datos que la componen

2. Identificar hasta qué punto pueden tener fabricantes y otros terceros a los datos que recogemos

   1. Priorizar siempre en la manera de los posible sensores que no utilicen las propias redes del fabricante, o de fabricante que garanticen no almacenar nada

   2. Analizar el tipo de dato que puede ser almacenado por dicho fabricante, valorar si puede identificar a personas físicas o si es considerado interno de la organización

   3. Analizar el tipo de uso que se va a dar en caso de que sí se recopile información, valorar si es aceptable, por ejemplo, utilizar datos que nosotros consideramos "abiertos" para mejora de sus servicios

3. Identificar si hay más puntos entre el punto de captura del dato y el lugar de almacenado final en el que pueda estar implicado un tercero

4. Re-evaluar los contextos y condiciones bajo las que se comparte información con otras organizaciones

## Herramientas

### Herramientas ETL

ETL, de sus siglas en inglés "Extract Transform Load" ("Extraer Transformar Cargar") es un proceso vital en el mundo de las IoT. Consiste principalmente en reunir datos de distintas fuentes, realizar un proceso para que queden uniformes y almacenarlos juntos. Es el único modo de tratar con orígenes de datos heterogéneos, que se dan tanto en los IoT, y poder utilizar dichos datos de forma conjunta posteriormente.

El procesado ha de ser guiado por un data steward que será quién especifique que forma final ha de tener los datos, es decir, qué estándares y condiciones tienen que cumplir. Por lo tanto será el trabajo de personas de perfil más técnico, como son los custodios el adaptar cada uno de los orígenes. Para ello se realizan los siguientes pasos:

1. Identificar todos los orígenes que han de ser agrupados

2. Identificar las salidas de cada uno de ellos

3. Definir las operaciones que han de realizarse sobre cada uno de ellos para transformarlos a lo que el steward ha especificado

4. Crear las entradas y operaciones identificadas y definidas anteriormente en la herramienta de ETL

#### Adeptia Connect

Adeptia Connect es una herramienta orientada a maximizar la facilidad de uso. Ofrece opciones para usuarios avanzados y con conocimientos más técnicos, pero busca ofrecer la mayoría de su funcionalidad como "no code" es decir puramente mediante su interfaz gráfica.

Es de licencia comercial, y su uso requiere de un contrato activo con Adeptia, no ofrecen opción de self-hosting. Toda la gestión se hace desde su plataforma, y sí ofrece algunos beneficios como el trabajo colaborativo de varias personas al mismo tiempo.

Ofrece procesamiento a tiempo real, además de algunas herramientas de monitorización.

#### Apache NiFi

Apache NiFi es una herramienta open-source, con soporte para procesamiento en vivo y opciones de procesado dinámico. De esta forma es posible realizar operaciones diferentes a los mismos orígenes dependiendo de condiciones establecidas.

Al ser open-source, sí dan la opción de gestionarla uno mismo, y aunque puede que no sea tan avanzada en el aspecto de la interfaz de usuario, sí que ofrece la mayoría de su funcionalidad directamente desde la interfaz web. Por lo que es posible funcionar correctamente con un equipo mixto de personas técnicas que se encarguen de el despliegue y funcionamiento del sistema, mientras que los menos técnicos se encargan de el uso de la herramienta.

#### IBM InfoSphere Information Server

Es una herramienta multiusos de IBM, que cuenta con su sección de ETL, aunque también busca ser una herramienta general para Data Warehousing y Business Intelligence, ofreciano la habilidad de gestionar la calidad del dato, análisis y auditoría.

Está optimizada para su uso conjunto con otras herramientas del

ecosistema IBM.

Puede ser utilizado desplegándolo en la organización mismo o en la nube.

#### Oracle Data Integration Cloud Service

Se trata de una plataforma completa, similar a la herramienta anterior de IBM, que busca unificar diferentes soluciones para todos los aspectos del gobierno del dato, Business Intelligence o migración de datos.

También se integra con las herramientas del ecosistema Oracle.

Es una herramienta orientada a su uso puramente en la nube, ya que la estrategia de Oracle ha sido la de desarrollar todo su ecosistema en la nube.

#### Comparativa

Realizamos la comparativa, principalmente valorando el tipo de licencia, precio, opciones para despliegues en la propia organización o en la nube e integraciones con herramientas del propio ecosistema.

| Herramienta                           | Licencia                    | Precio                                                  | Uso "in-premise" | Hosting en la nube            | Ecosistema                      |
| ------------------------------------- | --------------------------- | ------------------------------------------------------- | ---------------- | ----------------------------- | ------------------------------- |
| Adeptia Connect                       | Comercial                   | Bajo acuerdo                                            | Sí               | Sí, nube propia o de terceros | No cuenta con ecosistema propio |
| Apache NiFi                           | Apache License, Version 2.0 | Gratuito, a coste de realizar el mantenimiento nosotros | Sí               | Sí, nube de terceros          | Ecosistema Apache               |
| IBM InfoSphere Information Server     | Comercial                   | Bajo acuerdo                                            | Sí               | Sí, nube propia o de terceros | Ecosistema IBM                  |
| Oracle Data Integration Cloud Service | Comercial                   | Bajo acuerdo                                            | No               | Sí, nube propia               | Ecosistema Oracle               |

La elección de herramienta dependerá bastante de las capacidades técnicas del equipo, para equipos con pocos recursos de este tipo o que consideren que no pueden dedicarle los recursos necesarios, podrían considerar que la selección más correcta es alguna de las 3 que ofrecen soporte. Mientras que si nos consideramos habilitados para realizar esa gestión, la opción de Apache puede ser más adecuada, que es la que consideramos para nuestro caso. La elección de herramienta dependerá bastante de las capacidades técnicas del equipo, para equipos con pocos recursos de este tipo o que consideren que no pueden dedicarle los recursos necesarios, podrían considerar que la selección más correcta es alguna de las 3 que ofrecen soporte. Mientras que si nos consideramos habilitados para realizar esa gestión, la opción de Apache puede ser más adecuada, que es la que consideramos para nuestro caso.

La opción de integrarlos con servicios en la nube lo consideramos un punto a favor, pero sin embargo lo que se considera crítico es la opción de hosting en las premisas de la organización. Es la forma más sencilla de garantizar que ciertos datos no salen en ningún momento de nuestra organización.

Por lo tanto, se selecciona Apache NiFi como la solución más correcta en este caso, con la condición de que será necesario dedicar ciertos recursos a su gestión.

#### Usando Apache NiFi

NiFi funciona mediante lo que denomina "processors" que son las unidades que definen orígenes, transformaciones y salidas.

Un flujo de uso tal como se define en el manual [21] podría ser el siguiente, dividido para mostrar las 3 fases del proceso Extract-Transform-Load:

1. Extracción: Crear un nuevo processor de tipo  como de "data ingestion"

   1. Estos son los processors que formarán la entrada de todos nuestros datos

2. Transformación: procesadores que distribuyen los datos y los transforman

   1. Crear los procesadores dedicados a mover los datos

      1. De tipo "Routing" o "Mediator", es decir, que enrutan de un punto a otro

      2. De tipo "Attribute extraction", para extraer atributos concretos

      3. De tipo "Splitting" o "Merging", para separar atributos del mismo origen en varios, o de varios a un solo punto

   2. Crear los procesadores que transforman los datos en sí, de tipo "Data Transformation"

      1. Estos son los que realizan operaciones sobre los datos, como puede ser convertir de una unidad a otra

3. Carga:

   1. Procesadores que envían los datos ya transformados a su destino

      1. Tipo "Sending" para envío de datos a  el servidor donde configuremos

      2. Tipo "Database Access" si modificamos directamente en base de datos

Se definirá también el "run duration" o el tiempo que se dedicará a la ejecución de los procesadores cada vez que se pongan en marcha.

Finalmente definimos el momento de ejecución de los procesadores, en la pestaña de "scheduling".  La configuración principal es la estrategia de ejecución "Scheduling Strategy" que puede ser de 3 tipos:

- "Timer driven": ejecución continua cada X tiempo, para ejecución a tiempo real

- "Event driven": sólo se ejecuta bajo ciertas condiciones  especificadas

- "CRON driven": ejecuciones planificadas por fecha y hora. Por ejemplo, todas las semanas el viernes a las 2pm

Otras configuraciones más técnicas para la ejecución son las de "concurrent tasks" y "execution". La primera especifica cuantos hilos puede ocupar la ejecución, mientras que la segunda especifica el nodo específico en el que se ejecutan. Estas opciones no son definidas por el data steward, sino que se han de crear unas directrices por parte del equipo técnico que mantiene la herramienta para no sobrecargarla y hacer un uso óptimo de la misma.

### Herramientas de calidad del dato

De cara a utilizar una herramienta para gestionar la calidad del dato, ya que estamos utilizando Apache NiFi como herramienta ETL, optaremos por utilizarla también por sus cualidades de gestión de la calidad del dato para evitar redundancias con 2 herramientas que se solapan. De todas formas también se considerarán otras herramientas por si en algún futuro se decidiera dejar Apache NiFi de lado y se necesitara alguna alternativa.

#### Apache NiFi y la calidad del dato

Apache NiFi nos ofrece soporte para diferentes acciones clave de cara a la calidad:

| Validación                  | Es posible realizar una validación continua, ya sea mediante esquemas predefinidos o lógica programada                                                                                               |
| --------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Transformación              | La acción de la transformación en sí mejora la calidad, garantiza una estandarización  y consistencia de los datos.                                                                                  |
| Procedencia                 | NiFi muestra lo que llama el "linaje" de los datos, es decir muestra todos los pasos por los que transcurre desde el origen hasta la salida                                                          |
| Establecimiento de perfiles | O "data profiling", es la capacidad de NiFi de analizar la distribución de datos en el sistema, identificando patrones o posibles anomalías.                                                         |
| Limpieza                    | Parte de las operaciones que los "processors" pueden realizar son de limpieza de datos, como puede ser eliminación de duplicados o corregir errores                                                  |
| Gestión de errores          | Permite gestionar qué hacer en caso de errores, con políticas de reintentos o gestiones específicas. De esta forma se puede definir qué hacer al darse un fallo de validación o un error de conexión |
| Monitorización              | Permite monitorizar la salud y rendimiento de todos los aspectos del sistema, mostrando métricas de tasas de error, velocidades de procesamiento...                                                  |
| Logging                     | Alta customización de los logs del sistema, para poder identificar los fallos y trazar sus puntos de error                                                                                           |

#### Alternativas

Las primeras alternativas a considerar serían los ecosistemas de las otras herramientas ETL consideradas. En caso por ejemplo de pivotar a el ecosistema de IBM, también nos ofrecería capacidades de calidad del dato mediante sus propias herramientas. Es también el caso con Oracle Data Integration Cloud Service, que como se ha especificado antes, busca ser una herramienta que cubra todas las necesidades de este ámbito.

Otras alternativas existentes:

- OpenRefine, antes "Google Refine" es una herramienta dedicada exclusivamente a la calidad de la información, con especial énfasis en la eficiencia del análisis. Por lo que es una herramienta que destaca por ejemplo a la hora de identificar patrones en la información. Aunque es más limitada en el aspecto de la gestión de errores.

- Data Ladder, herramienta muy orientada a la limpieza de los datos. Sin embargo su muy limitado alcance y falta de documentación para sus características más avanzadas son un factor grande en su contra.

- Talend es una herramienta que potencia sus cualidades de análisis utilizando machine learning. Cuanta con varias rutinas de limpieza y de-duplicado muy eficientes, aunque su gran desventaja es la complejidad a la hora de usarse por parte de usuarios en perfiles poco técnicos.

### Catálogo de datos

Un catálogo de datos es un inventario de la riqueza del dato de una organización. No es un lugar para guardar los datos en sí, sino una recolección de metadatos sobre ellos. Es una forma de ayudar a los usuarios de dicha información a encontrar y acceder a ella de forma rápida y eficiente.

No debe de ser sólo aplicable a datos estructurados, sino que debe de permitir informar a los usuarios sobre todo tipo de diferentes tipos, especialmente importante en el ámbito de IoT, donde  se manejan decenas de formatos y estructuras.

Los dos usuarios principales de estos catálogos son por un lado los data stewards, encargados de organizar los datos de toda la organización realizando la tarea de mantenedores de el catálogo, y por otro lado los consumidores de la información, los cuales hacen uso de algún dato o conjunto de datos para servir a diferentes necesidades del negocio. Para estos segundos es de vital importancia el llegar a saber de qué pueden hacer uso, ya que muchas veces dada la gran cantidad de información es posible que ni siquiera se conozca. De la misma manera, y como hemos comentado antes sobre la gran heterogeneidad en el ámbito de las IoT, el catálogo especifica tanto de dónde puede recogerse esa información como la forma y estándares que tendrá.

También es una herramienta vital de cara a crear un lenguaje unificado. Este es el punto en el que los data stewards definen los datos, su nomenclatura, significado, clasificación y contexto. Y los demás consumidores han de usar el mismo lenguaje para así evitar posibles errores o confusiones.

#### Amudsen

Amudsen es una herramienta de catálogo de datos originalmente creada por Lyft y que ahora es de código abierto. Tiene un especial énfasis en la colaboración entre las personas usuarias, con capacidades para ver qué uso le dan las diferentes personas del equipo a las características de la herramienta como a qué tipo de datos se utilizan y de qué forma. Enfatiza el compartir con el resto del equipo anotaciones comentarios y valoraciones.

| Página web | https://www.amundsen.io/                |
| ---------- | --------------------------------------- |
| Licencia   | Apache-2.0 license                      |
| Proyecto   | https://github.com/amundsen-io/amundsen |

#### Collibra

Collibra es una de las soluciones líder en el mercado, ofreciando la mayoría de las características que son necesarias de una herramienta de este tipo para empresas. Es rápido en incluir nuevas tecnologías para mejorar sus funcionalidades, como es el caso de machine learning e inteligencia artificial, consiguiendo acelerar procesos de gestión de metadatos, clasificación y detección de anomalías.

Se trata de una solución completamente comercial, tanto en el sentido de no ser open source como de no contar con versión gratuita, todas sus funcionalidades requiren de un contrato con la empresa. Aunque sí es cierto que aunque sea sí que ofrecen dos modalidades, una puramente como servicio (es decir en su propia nube) y otra en las premisas de la organización usuaria.

| Página web | https://www.collibra.com/ |
| ---------- | ------------------------- |
| Licencia   | Comercial                 |
| Proyecto   | No es de código abierto   |

#### OpenMetadata

OpenMetadata es una herramienta de código abierto, una gran ventaja que ofrece es el poder realizar una demo directamente en su página web, de este modo es posible probar las funcionalidades incluso antes de hacer una primera instalación.

Ofrece la opción de ejecutar el catálogo directamente en cualquier servidor, o utilizar herramientas como Docker y Kubernetes o cualquier servicio cloud.

Se define a sí misma como la plataforma de metadatos con el mayor crecimiento en el mercado, y cuenta con amplia adopción en diferentes industrias.

Cuenta con herramientas de gestión y colaboración, y una amplia gama de conectores para todo tipo de entradas de datos.

| Página web | https://open-metadata.org/                    |
| ---------- | --------------------------------------------- |
| Licencia   | Apache-2.0 license                            |
| Proyecto   | https://github.com/open-metadata/OpenMetadata |

#### DataHub

DataHub es una solución mixta que cuenta con versiones gratuitas y open source (versión "Core") y comerciales (versión "Cloud"). Es una herramienta que tiene también gran presencia en la industria, y su versión Cloud está orientada a ofrecer servicios a empresas.

La versión Core cuenta con todas las funcionalidades básicas de un catálogo de datos maduro, pero hay ciertas características que son exclusivas de la versión Cloud, algunos ejemplos a continuación:

- Personalización de búsquedas para diferentes roles

- Automatizaciones con interfaz no-code

- Herramientas de IA para documentación

- Integraciones para ciertos datasources

- Seguimiento del flujo de información

- Observabilidad continua

- Evaluación de la calidad bajo demanda

Por lo que es cierto que la funcionalidad básica es gratuita, ofrece menos servicios que otras opciones que son puramente open source.

| Página web | https://datahub.com/                       |
| ---------- | ------------------------------------------ |
| Licencia   | Apache-2.0 license / comercial             |
| Proyecto   | https://github.com/datahub-project/datahub |

#### Comparativa

Para comparar las diferentes herramientas se valorará la permisividad de su licencia, tanto las opciones para realizar el mantenimiento nosotros mismo y por último las posibilidades de desplegarlo tanto en nuestras propias premisas como en la nube.

| Herramienta  | Open source | Precio                                         | Características completas  | Opción de despliegue "on premise" | Opción en cloud                                                           |
| ------------ | ----------- | ---------------------------------------------- | -------------------------- | --------------------------------- | ------------------------------------------------------------------------- |
| Amudsen      | Sí          | Gratuito                                       | Sí                         | Sí                                | Sí                                                                        |
| Collibra     | No          | Suscripción                                    | Sí                         | Sí                                | Sólo en su propio servicio                                                |
| OpenMetadata | Sí          | Gratuito                                       | Sí                         | Sí                                | Sí                                                                        |
| DataHub      | Mixto       | Gratuito para "Core", suscripción para "Cloud" | Sólo en la versión "Cloud" | Sólo en la versión "Core"         | En ambas versiones, aunque la versión "Cloud" ha de ser en su propia nube |

En conclusión, se han considerado principalmente Amudsen u OpenMetadata, ya que ofrecen la mayor flexibilidad posible, con opciones de despliegues por nuestra cuenta o en diferentes proveedores cloud. Tal como se ha valorado en la sección de "Herramientas ETL", se considera a nuestra organización lo suficientemente avanzada para realizar la gestión de la herramienta, y de este modo no queda el servicio atado a una suscripción recurrente.

La versión open source de DataHub se ha considerado que no es lo suficientemente madura comparada con las otras opciones de código abierto, y contaba con demasiadas limitaciones que sólo estaban presentes en la versión comercial.

Aunque tanto Amudsen como OpenMetadata se han considerado opciones adecuadas, se le ha dado la ventaja a OpenMetadata. Esto se da debido a su mayor madurez, facilidad de uso y gestión y mayor utilización en la industria. También por ofrecer una plataforma de pruebas online en la que los data stewards pueden andar realizando pruebas previa a la instalación, haciendo posible el pivotar a la otra opción en caso de identificar puntos que sean insuficientes.

Un último punto a considerar, es que sea compatible con la herramienta de ETL que estamos utilizando, Apache NiFi. En este caso OpenMetadata lo es, por lo que podemos darle el visto bueno.

#### Utilizando OpenMetadata

Dividiremos la siguiente sección en 2 partes, dependiendo de qué tipo de perfil sea el responsable de los distintos aspectos de la herramienta:

- Administradores: perfiles técnicos, encargados de el buen funcionamiento de la herramienta

- Usuarios: tanto data stewards que son los encargados de gestionar el dato como usuarios del dato. En general las acciones a realizar ya utilizando las prestaciones de gobernanza del dato que nos ofrece la herramienta

##### Administradores

La guía de administradores de OpenMetadata [22] divide las acciones básicas de administración de la plataforma en 3 secciones

1. Gestión de los usuarios y equipos

   1. Creación de los equipos

      1. OpenMetadata utiliza una estructura de la organización de 5 niveles: "Organization", "Business Unit", "Division", "Department" y "Group". Siendo Organization el nodo origen, cada nodo puede contener tanto nodos hijos de un tipo inferior o del mismo nivel (excepto Organization que no pueden ser del mismo nivel). Cada nodo puede tener varios nodos hijos, y en el caso de Department y Group pueden tener varios nodos padre también. Esto permite una forma flexible de adaptarse a casi cualquier organización.

      2. Los datos se asignarán a nivel de "Group", no de ningún nodo superior.

   2. Control de acceso

      1. OpenMetadata permite el acceso a la plataforma mediante varios servicios Single Sign On, como puede ser Auth0

      2. También permite definir políticas de acceso, estas así mismo puede ser de 3 tipos:

         1. "Evaluate Deny", significa que se evalúan las condiciones y si se da alguna se niega el acceso

         2. "Evaluate Allow", lo contrario, se evalúan y si se cumple alguna se otorga el acceso

         3. "Disallow Access", nunca se tiene acceso

2. Añadir los usuarios

   1. Desde el dashboard de OpenMetadata se pueden añadir los usuarios, se les asignan los datos básicos (nombre, correo electrónico, descripción) y su tipo dentro de la plataforma (Equipos a los que pertenece, roles y si se trata de un usuario administrador o no)

3. Configurar la entrada de metadatos

   1. OpenMetadata ofrece servicios para la conexión a diferentes orígenes, en especial para nuestro caso, cuenta un conector para Apache NiFi. También es posible configurar más de una entrada; por lo que si contáramos con datos no considerados en el ETL, aunque sería una mala práctica, podríamos seguir añadiéndolos a nuestro catálogo

   2. En este caso por lo tanto crearíamos un conector de tipo "Pipelines" y seleccionaríamos Apache NiFi

      1. Una vez creado se puede probar la conectividad y se podrá observar el estado de la conexión

   3. Dentro de cada conector se crearían los "Agents". En estos agentes se controla qué datos de los que expone de todos los que ofrece el origen a los que nos conectamos. De este modo podemos dar acceso a diferentes personas a diferentes recursos.

      1. Para cada agente se configurará también el momento de ejecución, que puede ser manual bajo demanda o planificado en momentos concretos

##### Usuarios

Es más complicado definir unos pasos iniciales para los usuarios dada la amplia extensión de la aplicación y los diferentes tipos de usos que cada usuario va a darle a la aplicación. Un buen punto de comienzo es el manual del usuario de OpenMetadata [23] en el que se detallan las diferentes secciones de la interfaz web, por lo que será la primera lectura necesaria para los usuarios. De esta forma será posible orientarse inicialmente y empezar a hacer uso de la herramienta.

Algunas de las secciones tratadas en el mismo son las siguientes:

- Página de inicio, se trata de una página viva y modificable por cada usuario, con una estructura de "widgets" cada usuario puede seleccionar cuales quiere ver en su página de inicio y en qué posición en orden.

  - Widgets de actividad: como puede ser un listado de la actividad de algún equipo, las menciones que hayan hecho otros usuarios o anuncios de alguien de la organización.

  - Widgets de tareas pendientes, creadas por el usuario mismo u otro usuario

  - Widgets de seguimiento: listados de recursos a los que el usuario sigue o widgets de rendimiento de recursos completos o de la aplicación entera.

- Gestión de los recursos, realizada directamente por el usuario o realizando solicitudes. Es decir que si el usuario descubre algún punto que requiera trabajo, puede decidir informarlo el mismo, o en caso de no saber puede mencionar a otro usuario para subsanar el problema.

  - Asignar titularidad, o modificar dicha titularidad

    - Por defecto la titularidad de un recurso se propaga hacia abajo (por ejemplo de un esquema de una base de datos a las tablas que lo compongan) a no ser que se especifique lo contrario

  -  Todos los recursos tienen ciertas características que se pueden configurar, como es la titularidad o el dominio, pero dependiendo de que tipo sean OpenMetadata ofrece unas pestañas de gestión u otras, para así sólo mostrar las que sean aplicables a el recurso en particular. Por ejemplo, un recurso de base de datos tendrá una pestaña para configurar sus esquemas, pero un recurso de tipo "pipeline" no tiene esquemas y por lo tanto no tendría sentido que tuviera esa pestaña. El manual de OpenMetadata especifica qué pestañas se aplican en cada caso [24]

  - Seguir un recurso, para luego poder verlo en la página principal y ser notificado de sus cambios

  - Eliminación de recursos

    - De forma lógica (OpenMetadata lo llama "soft delete"), de forma que el borrado sea reversible. A tener en cuenta que no cumple con regulaciones que requieran el eliminado real de datos

    - De forma física ("hard delete") para un borrado final que no es reversible

  - Descripciones de texto enriquecido mediante el uso de MarkDown

  - Creación de términos del glosario y etiquetas

  - Asignación de términos y etiquetas a recursos

  - Versionado de recursos

    - Pueden ser versiones menores (cambios no rompen compatibilidad) o mayores (sí se rompe compatibilidad)

  - Creación de propiedades a medida. Además de las propiedades por defecto para cada tipo de recurso, los usuarios podrán crear propiedades a medida para cubrir cualquier caso de uso no contemplado por defecto. Estas propiedades se relacionarán con un tipo de recurso concreto, y estarán disponibles para todos los recursos de dicho tipo.

## Monitorización

### Retos de la monitorización en el IoT

Los retos que la monitorización tiene que superar en el contexto del IoT vienen de aspectos que ya hemos tratado en otras secciones:

- Heterogeneidad de los sistemas: un reto que nos ha seguido en caso todo los pasos del proceso, sigue siendo igual de importante para la monitorización. Es imposible monitorizar correctamente todos estos sistemas sin un buen sistema de integración de todos ellos. Es por eso que se ha trabajado en utilizar herramientas que permitan esta estandarización y agregado de sistemas

- Problemas de conectividad: Al ser el IoT un ecosistema con muchísimos tipos de dispositivos separados en el espacio físico, es de gran importancia considerar que la tasa de fallos de conectividad será alta

- Generación masiva de datos: Es una de las ventajas del IoT que al mismo tiempo significa un reto, el IoT nos permite recopilar grandes cantidades de información que sistemas más centralizados son incapaces de alcanzar, pero esto supone un mayor coste a la hora de cualquier proceso que se de después de la captura del dato. Desde el transporte de altas cantidades, como el procesado de todos ellos y por supuesto la monitorización de todo ello

- Conformidad con las regulaciones: tratado principalmente en la sección de "Regulaciones", el ioT ofrece un reto extra no solo por la complejidad que aporta una mayor cantidad de datos, sino porque se dan muchas veces que son datos personales y la complicación que se da al considerar qué combinaciones de datos inicialmente no personales forman información personal

### Buenas prácticas

La creación de los procesos de monitorización no sigue los mismos pasos, pero sí que se pueden establecer buenas prácticas que guíen las decisiones:

- Utilizar siempre la herramienta de monitorización centralizada. Es decir no crear puntos de monitorización separados, se han de utilizar siempre las herramientas seleccionadas en el proyecto y la monitorización debe ir siempre por esos canales. De esta forma toda persona que deba acceder a esa monitorización podrá tener acceso a ella y se podrán realizar comparativas de los diferentes puntos.

- Identificar bases para las métricas, definir qué se considera el funcionamiento normal para cada una de las entradas y los rangos de valores para ese funcionamiento. Para ello es de vital importancia el haber establecido un lenguaje común en toda la organización, para que se vea claro qué conceptos son equivalentes (y por tanto se les puede aplicar los mismos rangos) y qué conceptos suenan igual pero no son equivalentes

- Crear alertas automáticas que avisen de cualquier problema. Identificar puntos críticos que requieran de intervención en caso de problemas, y utilizar las capacidades de nuestras herramientas para crear alertas. De esta forma dada una situación problemática las personas adecuadas estarán sobre aviso al momento

- Aplicar estándares de seguridad adecuados, de la misma forma que son necesarios para cualquier otro aspecto, en el ámbito de la monitorización es importante saber que datos se están moviendo a donde y cuando se trata de información personal o anonimizada.

### De cara al futuro

Prever las tendencias de cara al futuro es siempre complicado, y no es algo sobre lo que exista un consenso. Por ejemplo la plataforma de monitorización SigNoz contempla principalmente 4 tendencias [25]:

- El auge de la inteligencia artificial y el machine learning, utilizando sus capacidades para análisis predictivos para poder adelantarnos a problemas antes de que estos de den

- Integración de la tecnología 5G mejorando la conectividad de todos los dispositivos IoT, reduciendo problemas de conectividad, mejorando el rendimiento de las comunicaciones tanto en el ancho de banda como en latencia. Mejorando de gran manera el rendimiento de cualquier procesado

- "Edge Computing" para un mayor procesado desde el principio, disminuyendo el trabajo a realizar por herramientas centralizadas que ya recibirán la información más estandarizada y procesada. De esta forma no se consumirán tantos recursos en un solo punto, sino que se repartirá parte de la carga por todo el sistema

- Blockchain para el aumento de la seguridad e integridad, creando registros transparentes e inmutables

## Referencias

[1] ¿Qué es la gobernanza de datos? | Definición, importancia y tipos | SAP. (n.d.). SAP. https://www.sap.com/latinamerica/products/data-cloud/master-data-governance/what-is-data-governance.html

[2] EWSolutions. (2025, March 20). Data Governance Program Team structure. EWSolutions. https://www.ewsolutions.com/data-governance-program-team-structure/

[3] Kazlow, D. (2024, September 18). The definitive guide to Data Governance Councils - The Data Governance. The Data Governance. https://thedatagovernance.com/data-governance-council/

[4] Firican, G. (2021, November 22). The complete guide to data governance roles and responsibilities | LightsOnData. LightsOnData. https://www.lightsondata.com/the-complete-guide-to-data-governance-roles-and-responsibilities/

[5] IoT-Lite Ontology. (n.d.). https://www.w3.org/submissions/2015/SUBM-iot-lite-20151126/

[6] Atlan, T. (2024, December 18). Data Governance Policy: Comprehensive Guide with Examples for 2025. Atlan. https://atlan.com/data-governance-policy/

[7] General Data Protection Regulation (GDPR) – Legal Text. (2024, April 22). General Data Protection Regulation (GDPR). https://gdpr-info.eu/

[8] Personal Data - General Data Protection Regulation (GDPR). (2021, October 22). General Data Protection Regulation (GDPR). https://gdpr-info.eu/issues/personal-data/

[9] Encryption - General Data Protection Regulation (GDPR). (2023, September 5). General Data Protection Regulation (GDPR). https://gdpr-info.eu/issues/encryption/

[10] Internet Society (2020). Policy Toolkit on IoT Security and Privacy : https://www.internetsociety.org/wp-content/uploads/2020/08/IoTtoolkit-August-2020.pdf

[11] Vinod V. Nair, R. Nanda Kishor. (2017). Getting the Most out of IoT with an Effective Data Lifecycle Management Strategy. https://www.tcs.com/content/dam/global-tcs/en/pdfs/insights/whitepapers/getting-the-most-of-iot-data-effective-lifecycle-management-strategy.pdf

[12] Baker, E. (2024, September 26). Conducting a data governance audit. DataGovernancePlatforms.com. https://www.datagovernanceplatforms.com/conducting-data-governance-audit/

[13] The Institute of Internal Auditors, Inc (2020). Data Governance - Providing assurance regarding data risk management : https://www.theiia.org/globalassets/site/content/articles/industry-knowledge-brief/2020/data-governance/data-governance.pdf

[14] BOE-A-2018-16673 Ley Orgánica 3/2018, de 5 de diciembre, de Protección de Datos Personales y garantía de los derechos digitales. (n.d.). https://www.boe.es/buscar/doc.php?id=BOE-A-2018-16673

[15] datos.gob.es. (2025c, March 10). Especificaciones UNE – Gobierno, gestión y calidad del dato. datos.gob.es. https://datos.gob.es/es/blog/especificaciones-une-gobierno-gestion-y-calidad-del-dato

[16] datos.gob.es. (2025d, June 6). Aplicación de la especificación UNE 0077:2023 a los datos abiertos. datos.gob.es. https://datos.gob.es/es/blog/aplicacion-de-la-especificacion-une-00772023-los-datos-abiertos

[17] datos.gob.es. (2025e, June 6). Aplicación de las Especificación UNE 0078:2023 a los datos abiertos. datos.gob.es. https://datos.gob.es/es/blog/aplicacion-de-las-especificacion-une-0078-2023-los-datos-abiertos

[18] datos.gob.es. (2025e, June 6). Aplicación de la Especificación UNE 0079:2023 de gestión de calidad a los datos abiertos. datos.gob.es. https://datos.gob.es/es/blog/aplicacion-de-la-especificacion-une-00792023-de-gestion-de-calidad-los-datos-abiertos

[19] Art. 4 GDPR – Definitions - General Data Protection Regulation (GDPR). (2018, March 29). General Data Protection Regulation (GDPR). https://gdpr-info.eu/art-4-gdpr/

[20] Asswad, J., & Marx Gómez, J. (2021). Data Ownership: A Survey. Information, 12(11), 465. https://doi.org/10.3390/info12110465

[21] Team, A. N. (n.d.). Apache NiFi User Guide. https://nifi.apache.org/docs/nifi-docs/html/user-guide.html

[22] Admin Guide | OpenMetadata Administration Documentation. (n.d.). https://docs.open-metadata.org/latest/how-to-guides/admin-guide

[23] Guide for Data Users | OpenMetadata User Guide. (n.d.). https://docs.open-metadata.org/latest/how-to-guides/guide-for-data-users

[24] Overview of Data Assets. (n.d.). https://docs.open-metadata.org/latest/how-to-guides/guide-for-data-users/data-asset-tabs#data-asset-tabs

[25] Goswami, V. (2024, November 29). Essential Guide to IoT Monitoring - Benefits and Best Practices. SigNoz. https://signoz.io/guides/iot-monitoring/